{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I7_hzaMrkEyW"
      },
      "outputs": [],
      "source": [
        "pip install langchain langchain-community faiss-cpu pypdf gradio sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunks = splitter.split_documents(documents)\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "SVzYgjDAkNm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "FEQVcW5HkRSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "def build_faiss_index(chunks, embeddings_model):\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings_model)\n",
        "    return vectorstore\n"
      ],
      "metadata": {
        "id": "Areqwm6akT_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, vectorstore, k=4):\n",
        "    docs = vectorstore.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "ypcVnBsDkWci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a medical communication expert. Your job is to translate complex medical documents into simple, easy-to-understand summaries for regular people, such as patients and their families.\"\n",
        "    ),\n",
        "    (\"human\",\n",
        "     \"The user has uploaded a medical document:\\n\\n{context}\\n\\n\"\n",
        "     \"Please read the document and generate a short, clear summary in layman’s terms. Follow these rules:\\n\"\n",
        "     \"1. 🩺 If it’s a **medical report for a patient**, explain:\\n\"\n",
        "     \"   - What the diagnosis or health issue is (in simple words).\\n\"\n",
        "     \"   - What symptoms were mentioned.\\n\"\n",
        "     \"   - What treatments or medicines are prescribed.\\n\"\n",
        "     \"   - Any advice, precautions, or next steps.\\n\\n\"\n",
        "     \"2. 📚 If it’s a **research paper or technical document**, explain:\\n\"\n",
        "     \"   - What the report is about (its purpose).\\n\"\n",
        "     \"   - Key findings and conclusions.\\n\"\n",
        "     \"   - Why it matters (in simple terms).\\n\\n\"\n",
        "     \"✅ Avoid medical jargon. Write like you are explaining to a friend or family member.\\n\"\n",
        "     \"✅ Keep it friendly, helpful, and around 150–200 words.\\n\"\n",
        "     \"✅ Use bullets or short paragraphs if needed.\\n\"\n",
        "     \"✅ Don’t say 'this is a research paper' or 'this is a medical report'. Just start summarizing naturally.\"\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "lMXMr-SNkYn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efKhkW_Tk9_R",
        "outputId": "489ace8b-a3b8-4dec-b71c-e8b47ac65df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (0.3.6)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.68)\n",
            "Requirement already satisfied: groq<1,>=0.29.0 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.30.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (4.14.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.29.0->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=\"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\",\n",
        "    model_name=\"llama3-70b-8192\",\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "iSlC84UJkZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def summarize_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"Please upload a PDF.\"\n",
        "\n",
        "    # Gradio has already saved the file\n",
        "    tmp_path = pdf_file.name\n",
        "\n",
        "    # Process PDF\n",
        "    chunks = load_and_chunk_pdf(tmp_path)\n",
        "    vectorstore = build_faiss_index(chunks, embeddings_model)\n",
        "\n",
        "    # Define the retrieval query\n",
        "    query = (\n",
        "        \"Summarize this medical report for a patient in simple and easy language, \"\n",
        "        \"including the disease name, symptoms, prescribed medicines, and any precautions. \"\n",
        "        \"Avoid complex medical jargon. Use short sentences., make it short and relevant, dont just state the full report in the output\"\n",
        "\n",
        "    )\n",
        "\n",
        "    # Retrieve relevant context\n",
        "    context = retrieve_context(query, vectorstore, k=4)\n",
        "\n",
        "    # Run RAG chain\n",
        "    summary = chain.invoke({\"context\": context})\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "\n",
        "# demo = gr.Interface(\n",
        "#     fn=summarize_pdf,\n",
        "#     inputs=gr.File(label=\"Upload your PDF\"),\n",
        "#     outputs=gr.Textbox(label=\"Layman's Summary\", lines=10),\n",
        "#     title=\"Medical PDF Summarizer (RAG: Groq + Hugging Face + FAISS)\",\n",
        "#     description=\"Upload a medical report PDF, and I'll summarize it in simple terms using retrieval-augmented generation.\"\n",
        "# )\n",
        "\n",
        "# demo.launch(share=True, debug=True)\n",
        "with gr.Blocks(theme=gr.themes.Soft(), css=\"\"\"\n",
        ".gradio-container { background-color: #0f0f0f !important; color: #e0e0e0; }\n",
        ".gr-button { background-color: #00cc66 !important; color: white !important; border-radius: 8px !important; }\n",
        ".gr-button:hover { background-color: #00b359 !important; }\n",
        ".gr-textbox textarea { background-color: #1a1a1a !important; color: #e0e0e0; border-radius: 6px; }\n",
        "\"\"\") as demo:\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 📝 Upload Your Medical Report\")\n",
        "            file_input = gr.File(label=\"Upload your PDF\", file_types=[\".pdf\"])\n",
        "            submit_btn = gr.Button(\"🔍 Generate Summary\")\n",
        "            gr.Markdown(\"<br><center>❤ Powered for Patients</center>\")\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### ✅ Patient-Friendly Medical Summary\")\n",
        "            output_text = gr.Textbox(label=\"Layman's Summary\", lines=10, placeholder=\"Your patient-friendly medical summary will appear here...\")\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=summarize_pdf,\n",
        "        inputs=file_input,\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "dIgrEUUHkcds",
        "outputId": "2dffd8b4-ef89-42be-bea8-72cdd412139a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1f5f394893d68fc3af.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1f5f394893d68fc3af.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1f5f394893d68fc3af.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}